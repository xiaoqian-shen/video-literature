# Awesome Papers on Video/3D Generation and Representation 

## Video Generation

### Unconditional

#### 2022

VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution

[paper](https://arxiv.org/abs/2206.04647) [code](https://github.com/Picsart-AI-Research/VideoINR-Continuous-Space-Time-Super-Resolution) CVPR

Generating Long Videos of Dynamic Scenes

[paper](http://arxiv.org/abs/2206.03429) [no code](https://www.timothybrooks.com/tech/long-videos/)

Video2StyleGAN: Disentangling Local and Global Variations in a Video

[paper](https://arxiv.org/abs/2205.13996v2)

Video Diffusion Models

[paper](http://arxiv.org/abs/2204.03458)

TATS: Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer

[paper](http://arxiv.org/abs/2204.03638) [code](https://github.com/SongweiGe/TATS)

V3GAN: Decomposing Background, Foreground and Motion for Video Generation

[paper](https://arxiv.org/abs/2203.14074v1)

```
Three stream generator (spatially, temporally and video). Factorized spatio-temporal Self-Attention
```

DIGAN: Generating Videos with Dynamics-aware Implicit Generative Adversarial Networks

[paper](http://arxiv.org/abs/2202.10571) [code]((https://github.com/sihyun-yu/digan)) ICLR

#### 2021

StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2

[paper](http://arxiv.org/abs/2112.14683) [code](https://github.com/universome/stylegan-v) CVPR

VideoGPT: Video Generation using VQ-VAE and Transformers

[paper]((https://arxiv.org/abs/2104.10157)) [code](https://github.com/wilson1yan/VideoGPT)

Generative Video Transformer: Can Objects be the Words?

[paper](http://arxiv.org/abs/2107.09240) ICML

StyleVideoGAN: A Temporal Generative Model using a Pretrained StyleGAN

[paper](https://arxiv.org/abs/2107.07224v2) 

MoCoGAN-HD: A Good Image Generator Is What You Need for High-Resolution Video Synthesis

[paper](https://arxiv.org/abs/2104.15069v1) [code](https://github.com/snap-research/MoCoGAN-HD) ICLR

InMoDeGAN: Interpretable Motion Decomposition Generative Adversarial Network for Video Generation

[paper](https://arxiv.org/abs/2101.03049v1)

Temporal Shift GAN for Large Scale Video Generation

[paper](https://openaccess.thecvf.com/content/WACV2021/papers/Munoz_Temporal_Shift_GAN_for_Large_Scale_Video_Generation_WACV_2021_paper.pdf) WACV

#### 2020

Infinite Nature: Perpetual View Generation of Natural Scenes from a Single Image

[paper](https://arxiv.org/abs/2012.09855v4) ICCV(oral)

Learning Temporal Coherence via Self-Supervision for GAN-based Video Generation

[paper](http://arxiv.org/abs/1811.09393) ACM(Graphics)

G3AN: Disentangling Appearance and Motion for Video Generation

[paper](https://ieeexplore.ieee.org/document/9157816/) CVPR

#### 2018

MoCoGAN: Decomposing Motion and Content for Video Generation

[paper](https://ieeexplore.ieee.org/document/8578263/) CVPR

#### 2017

TGAN: Temporal Generative Adversarial Nets with Singular Value Clipping

[paper](http://ieeexplore.ieee.org/document/8237570/) ICCV

#### 2016

Generating Videos with Scene Dynamics

[paper](https://proceedings.neurips.cc/paper/2016/hash/04025959b191f8f9de3f924f0940515f-Abstract.html) NeurIPS

### Conditional

#### 2022

Temporally Consistent Semantic Video Editing

[paper](https://arxiv.org/abs/2206.10590v1)

CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers

[paper](https://arxiv.org/abs/2205.15868v1)

MUGEN: A Playground for Video-Audio-Text Multimodal Understanding and GENeration

[paper](https://arxiv.org/abs/2204.08058v3)

Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning

[paper](http://arxiv.org/abs/2203.02573) CVPR

#### 2021

CCVS: Context-aware Controllable Video Synthesis

[paper](http://arxiv.org/abs/2107.08037) NeurIPS

#### 2020

ImaGINator: Conditional Spatio-Temporal GAN for Video Generation

[paper](https://ieeexplore.ieee.org/document/9093492/) WACV

#### 2019

Conditional GAN with Discriminative Filter Generation for Text-to-Video Synthesis

[paper](https://www.ijcai.org/proceedings/2019/276) IJCAI



## Video Representation



#### 2022

MCL: Motion-Focused Contrastive Learning of Video Representations

[paper](https://arxiv.org/abs/2201.04029v1) ICCV(oral)

#### 2021

FAME: Motion-aware Contrastive Video Representation Learning via Foreground-background Merging

[paper](https://arxiv.org/abs/2109.15130v3) CVPR

TAM: Temporal Adaptive Module for Video Recognition

[paper](http://arxiv.org/abs/2005.06803) ICCV

Self-supervised Video Representation Learning by Context and Motion Decoupling

[paper](https://arxiv.org/abs/2104.00862v1) CVPR

Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion

[paper](https://arxiv.org/abs/2009.05757v3) AAAI

## Others

3D-Aware Video Generation

[paper](https://arxiv.org/abs/2206.14797v1)

Latent Image Animator: Learning to Animate Images via Latent Space Navigation

[paper](https://arxiv.org/abs/2203.09043v1) ICLR2022